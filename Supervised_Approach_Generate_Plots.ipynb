{"cells":[{"cell_type":"markdown","metadata":{"id":"yxJaI2hOYFNP"},"source":["#Funciones y librerías"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26691,"status":"ok","timestamp":1743193958370,"user":{"displayName":"Diego Armando Perez Rosero","userId":"06154535922612881248"},"user_tz":300},"id":"K5MEWDu12jEa","outputId":"e14d0a68-3eb4-4a0f-8ed2-0ec4fd3f1d78"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# ========================================\n","# 1. Instalación de librerías externas\n","# ========================================\n","!pip install pmdarima==1.8.5\n","!pip install -q -U keras-tuner\n","\n","# ========================================\n","# 2. Librerías base y utilidades generales\n","# ========================================\n","import warnings\n","import numpy as np\n","import pandas as pd\n","from tabulate import tabulate\n","\n","# ========================================\n","# 3. Visualización\n","# ========================================\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# ========================================\n","# 4. Preprocesamiento de datos\n","# ========================================\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.pipeline import Pipeline\n","\n","# ========================================\n","# 5. Modelos de regresión clásicos\n","# ========================================\n","from sklearn.linear_model import LinearRegression, Lasso, ElasticNet, SGDRegressor, BayesianRidge\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.svm import SVR\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.kernel_ridge import KernelRidge\n","\n","# ========================================\n","# 6. Modelos bayesianos y de procesos gaussianos\n","# ========================================\n","from sklearn.gaussian_process import GaussianProcessRegressor\n","from sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel, Matern, ExpSineSquared, DotProduct\n","\n","# ========================================\n","# 7. Modelos estadísticos y series temporales\n","# ========================================\n","import pmdarima as pm\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.tsa.arima.model import ARIMA\n","from statsmodels.tools.sm_exceptions import ConvergenceWarning\n","\n","# ========================================\n","# 8. Evaluación de modelos\n","# ========================================\n","from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n","\n","# ========================================\n","# 9. Keras Tuner para ajuste de hiperparámetros\n","# ========================================\n","from keras_tuner import BayesianOptimization as OriginalBayesianOptimization\n","from keras_tuner.oracles import BayesianOptimizationOracle as OriginalBayesianOptimizationOracle\n","from keras_tuner import Tuner, Objective\n","from keras_tuner.tuners import SklearnTuner\n","from keras_tuner.src.engine import hyperparameters as hp_module\n","from keras_tuner.src.engine import oracle as oracle_module\n","from keras_tuner.src.engine import trial as trial_module\n","from keras_tuner.src.engine import tuner as tuner_module\n","from keras_tuner.src.api_export import keras_tuner_export\n","\n","# ========================================\n","# 10. Configuración de warnings\n","# ========================================\n","warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Non-stationary starting autoregressive parameters found\")\n","warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Non-invertible starting MA parameters found\")\n","warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, message=\"Maximum Likelihood optimization failed to converge\")\n","\n","class CustomBayesianOptimizationOracle(OriginalBayesianOptimizationOracle):\n","    def __init__(self, *args, nu=0.5, **kwargs):\n","        self.nu = nu  # Establecer nu antes de llamar al constructor de la clase base\n","        super().__init__(*args, **kwargs)\n","        self.gpr = self._make_gpr()  # Asegurarse de que _make_gpr se llame después de establecer nu\n","    def _gpr_trained(self):\n","        if self.gpr is None:\n","            print(\"There is no GPR model trained yet.\")\n","            return None\n","        else:\n","            return self.gpr\n","    def _make_gpr(self):\n","        return sklearn.gaussian_process.GaussianProcessRegressor(\n","            kernel=sklearn.gaussian_process.kernels.Matern(nu=self.nu),\n","            n_restarts_optimizer=20,\n","            normalize_y=True,\n","            alpha=self.alpha,\n","            random_state=self.seed,\n","        )\n","\n","class CustomBayesianOptimization(Tuner):\n","    def __init__(\n","        self,\n","        hypermodel=None,\n","        objective=None,\n","        max_trials=10,\n","        num_initial_points=None,\n","        alpha=1e-4,\n","        beta=2.6,\n","        seed=None,\n","        hyperparameters=None,\n","        tune_new_entries=True,\n","        allow_new_entries=True,\n","        max_retries_per_trial=0,\n","        max_consecutive_failed_trials=3,\n","        nu=0.5,  # Valor por defecto para nu\n","        **kwargs\n","    ):\n","        oracle = CustomBayesianOptimizationOracle(\n","            objective=objective,\n","            max_trials=max_trials,\n","            num_initial_points=num_initial_points,\n","            alpha=alpha,\n","            beta=beta,\n","            seed=seed,\n","            hyperparameters=hyperparameters,\n","            tune_new_entries=tune_new_entries,\n","            allow_new_entries=allow_new_entries,\n","            max_retries_per_trial=max_retries_per_trial,\n","            max_consecutive_failed_trials=max_consecutive_failed_trials,\n","            nu=nu  # Pasar el parámetro nu\n","        )\n","        # Llama directamente al constructor de la clase base Tuner\n","        super().__init__(oracle=oracle, hypermodel=hypermodel, **kwargs)\n","\n","class CustomSklearnBayesianOptimization(SklearnTuner):\n","    def __init__(\n","        self,\n","        hypermodel=None,\n","        objective=None,\n","        max_trials=10,\n","        num_initial_points=None,\n","        alpha=1e-1,\n","        beta=2.6,\n","        seed=None,\n","        hyperparameters=None,\n","        tune_new_entries=True,\n","        allow_new_entries=True,\n","        max_retries_per_trial=0,\n","        max_consecutive_failed_trials=3,\n","        nu=0.5,  # Valor por defecto para nu\n","        scoring=None,\n","        cv=None,\n","        **kwargs\n","    ):\n","        oracle = CustomBayesianOptimizationOracle(\n","            objective=objective,\n","            max_trials=max_trials,\n","            num_initial_points=num_initial_points,\n","            alpha=alpha,\n","            beta=beta,\n","            seed=seed,\n","            hyperparameters=hyperparameters,\n","            tune_new_entries=tune_new_entries,\n","            allow_new_entries=allow_new_entries,\n","            max_retries_per_trial=max_retries_per_trial,\n","            max_consecutive_failed_trials=max_consecutive_failed_trials,\n","            nu=nu  # Pasar el parámetro nu\n","        )\n","        # Llama directamente al constructor de la clase base SklearnTuner\n","        super().__init__(oracle=oracle, hypermodel=hypermodel, scoring=scoring, cv=cv, **kwargs)\n","class TimeSeriesPipeline:\n","    def __init__(self, model_type='SARIMA', seasonal=True, scaler=None, m=12):\n","        self.model_type = model_type\n","        self.scaler = scaler\n","        self.model = None\n","        self.seasonal = seasonal\n","        self.m = m  # Número de períodos en una temporada para SARIMA\n","    def fit(self, y_train):\n","        # Aplicar escalado si se proporciona\n","        if self.scaler:\n","            y_train = self.scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n","        # Utilizar auto_arima para encontrar los mejores parámetros\n","        model_auto = auto_arima(\n","            y_train,\n","            seasonal=self.seasonal,\n","            m=self.m,\n","            trace=False,\n","            error_action='ignore',\n","            suppress_warnings=True,\n","            stepwise=True\n","        )\n","        try:\n","            order = model_auto.order\n","        except:\n","            model_auto = auto_arima(\n","            y_train,\n","            seasonal=self.seasonal,\n","            m=1,\n","            trace=False,\n","            error_action='ignore',\n","            suppress_warnings=True,\n","            stepwise=True)\n","        order = model_auto.order\n","        seasonal_order = model_auto.seasonal_order if self.seasonal else (0, 0, 0, 0)\n","        # Ajustar el modelo basado en el tipo especificado\n","        if self.model_type == 'ARIMA':\n","            self.model = ARIMA(y_train, order=order).fit()\n","        elif self.model_type == 'SARIMA':\n","            self.model = SARIMAX(y_train, order=order, seasonal_order=seasonal_order).fit()\n","        # Guardar la información del modelo ajustado\n","        self.model_info = {\n","            'order': order,\n","            'seasonal_order': seasonal_order,\n","            'aic': self.model.aic,\n","            'bic': self.model.bic\n","        }\n","    def predict(self, start, end):\n","        # Realizar predicciones\n","        y_pred = self.model.predict(start=start, end=end)\n","        # Invertir escalado si se proporcionó\n","        if self.scaler:\n","            y_pred = self.scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n","        return y_pred\n","# Clase TimeSeriesPipeline ya definida aquí...\n","def build_pipeline(hp, y_train, model_type='KRRBF', seasonal_order=(1, 1, 1, 4), X=X):\n","    # Estándarización\n","    scaler = MinMaxScaler()\n","\n","    # Definición del modelo basado en el tipo\n","    if model_type == \"KRRBF\":\n","        model = KernelRidge(\n","            kernel='rbf',\n","            gamma=hp.Float(\"gamma\", 1e-3, 100, default=1, sampling=\"log\"),\n","            alpha=hp.Float(\"alpha\", 1e-3, 100, default=1, sampling=\"log\")\n","        )\n","    elif model_type == \"KNN\":\n","        model = KNeighborsRegressor(\n","            n_neighbors=hp.Int(\"n_neighbors\", 1, 9, default=3)\n","        )\n","    elif model_type == \"GP\":\n","        model = GaussianProcessRegressor(\n","            alpha=hp.Float(\"alpha\", 1e-5, 1e2, default=1, sampling=\"log\"),\n","            kernel=RBF(length_scale=np.ones(X.shape[1]),length_scale_bounds=(1,1000))#WhiteKernel()+Matern(,nu=0.5),normalize_y=True,\n","        )\n","    elif model_type == \"Linear\":\n","        model = LinearRegression()\n","    elif model_type == \"Lasso\":\n","        model = Lasso(\n","            alpha=hp.Float(\"alpha\", 1e-3, 1, default=1, sampling=\"log\")\n","        )\n","    elif model_type == \"Elastic\":\n","        model = ElasticNet(\n","            alpha=hp.Float(\"alpha\", 0.1, 1, sampling=\"log\"),\n","            l1_ratio=hp.Float(\"l1_ratio\", 0.1, 1,sampling=\"log\")\n","        )\n","    elif model_type == \"SGD\":\n","        model = SGDRegressor(\n","            alpha=hp.Float(\"alpha\", 1e-3, 1, default=0.01, sampling=\"log\"),\n","            l1_ratio=hp.Float(\"l1_ratio\", 0, 1, default=0.15)\n","        )\n","    elif model_type == \"BayesRid\":\n","        model = BayesianRidge(\n","            alpha_1=hp.Float(\"alpha_1\", 1e-6, 1, default=1e-6, sampling=\"log\"),\n","            alpha_2=hp.Float(\"alpha_2\", 1e-6, 1, default=1e-6, sampling=\"log\"),\n","            lambda_1=hp.Float(\"lambda_1\", 1e-6, 1, default=1e-6, sampling=\"log\"),\n","            lambda_2=hp.Float(\"lambda_2\", 1e-6, 1, default=1e-6, sampling=\"log\")\n","        )\n","    elif model_type == \"RF\":\n","        model = RandomForestRegressor(\n","            max_depth=hp.Int(\"max_depth\", 1, 100, step=1, default=30),\n","            n_estimators=hp.Int(\"n_estimators\", 1, 100, step=1, default=70)\n","        )\n","    elif model_type == \"SVR\":\n","        model = SVR(\n","            kernel=hp.Choice(\"kernel\", ['linear', 'poly', 'rbf', 'sigmoid'], default='rbf'),\n","            C=hp.Float(\"C\", 0.1, 1, default=1),\n","            epsilon=hp.Float(\"epsilon\", 1e-3, 0.1, default=0.1, sampling=\"log\")\n","        )\n","    elif model_type in ['ARIMA', 'SARIMA']:\n","        # Crear una instancia de TimeSeriesPipeline para ARIMA o SARIMA\n","        seasonal = (model_type == 'SARIMA')\n","        ts_pipeline = TimeSeriesPipeline(\n","            model_type=model_type,\n","            seasonal=seasonal,\n","            scaler=scaler,\n","            m=seasonal_order[3] if seasonal else 1\n","        )\n","        # Ajustar el modelo con los datos de entrenamiento\n","        ts_pipeline.fit(y_train)\n","        # Retornar el modelo ajustado y la información del modelo\n","        fitted_model = ts_pipeline\n","        model_info = ts_pipeline.model_info\n","        return fitted_model, model_info\n","    else:\n","        raise ValueError(\"Unrecognized model_type\")\n","    # Creación del pipeline para los modelos de ML estándar\n","    pipeline =Pipeline([(\"reg\", model)]) #Pipeline([('sca',scaler),(\"reg\", model)])\n","    return pipeline\n","class ModelBuilder:\n","    def __init__(self, model_type, y_train, seasonal_order=(1, 1, 1, 3)):\n","        self.model_type = model_type\n","        self.seasonal_order = seasonal_order\n","        self.y_train = y_train\n","    def build_model(self, hp):\n","        return build_pipeline(hp, self.y_train, self.model_type, self.seasonal_order)\n","path='/content/drive/MyDrive/Doctorado/Optimización/'\n","def time_series_cv(X, y, model_type='KRRBF', s=0, Na='', seasonal_order=(1, 1, 1, 1),train_years = 1,test_months = 3,step_months = 3 ):\n","    tuners = []\n","    Cont = 0\n","    y_true_list = []\n","    y_pred_list = []\n","    y_std_list = []\n","    best_params_list = []\n","      # Años para entrenamiento\n","      # Meses para predicción\n","     # Meses para mover hacia adelante\n","    for ind in range(12, X.shape[0] - test_months + 1, step_months):\n","        # Definir los intervalos de entrenamiento y prueba\n","        X_train, y_train = X[(ind - train_years * 12)*s:ind], y[(ind - train_years * 12)*s:ind]\n","        X_test, y_test = X[ind:ind + test_months], y[ind:ind + test_months]\n","        if model_type in ['ARIMA', 'SARIMA']:\n","            model,best_params = ModelBuilder(model_type, y_train, seasonal_order).build_model(2)\n","            y_pred = model.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1)\n","        else:\n","            model_builder = ModelBuilder(model_type, y_train, seasonal_order)\n","            tuner = CustomSklearnBayesianOptimization(\n","                hypermodel=model_builder.build_model,\n","                objective=Objective('score', direction='max'),\n","                max_trials=15,\n","                scoring=make_scorer(r2_score),\n","                directory='.',\n","                cv=None,\n","                project_name=f'12{Na}CV{Cont}_{model_type}'\n","            )\n","            print(Cont)\n","            Cont += 1\n","            tuner.search(X_train, y_train)\n","            tuners.append(tuner)\n","            # Obtener y evaluar el mejor modelo de este fold\n","            best_model = tuner.get_best_models(num_models=1)[0]\n","            best_params = tuner.get_best_hyperparameters()[0].values\n","            if model_type == 'GP':\n","                kernel_params = best_model.get_params()['reg'].kernel_.get_params()\n","                best_params.update(kernel_params)\n","                y_pred, y_std = best_model.predict(X_test, return_std=True)\n","                y_std_list.extend(y_std)\n","            elif model_type in  ['Lasso','Elastic']:\n","                # Extraer coeficientes de ElasticNet\n","                final_model = best_model.named_steps['reg']\n","                coef_params = final_model.coef_\n","                best_params.update({'coef_' + str(i): coef for i, coef in enumerate(coef_params)})\n","                y_pred = best_model.predict(X_test)\n","            elif model_type == 'RF':\n","                final_model = best_model.named_steps['reg']\n","                importances = final_model.feature_importances_\n","                best_params.update({'feature_importance_' + str(i): imp for i, imp in enumerate(importances)})\n","                y_pred = best_model.predict(X_test)\n","            else:\n","                y_pred = best_model.predict(X_test)\n","        best_params_list.append(best_params)\n","        y_true_list.extend(y_test)\n","        y_pred_list.extend(y_pred)\n","    # Guardar y_true, y_pred y y_std (si existe) en un archivo Excel\n","    results_dict = {'y_true': y_true_list, 'y_pred': y_pred_list}\n","    if y_std_list:\n","        results_dict['y_std'] = y_std_list\n","    y_results = pd.DataFrame(results_dict)\n","    y_results_file_path = f'{path}{test_months} Meses/Results/{model_type}_{s}.xlsx'\n","    y_results.to_excel(y_results_file_path, index=False)\n","    # Guardar los mejores hiperparámetros (incluyendo kernel si aplica) en un archivo Excel\n","    best_params_df = pd.DataFrame(best_params_list)\n","    best_params_file_path = f'{path}{test_months} Meses/Params/{model_type}_{s}.xlsx'\n","    best_params_df.to_excel(best_params_file_path, index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"CGGIGYweOG-N"},"source":["#Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KsviLDjF2Ply"},"outputs":[],"source":["FILEID =\"1BidLKcEXF6h-LKKWixtKmQ_g5hgvrkgd\"\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O datos.xlsx && rm -rf /tmp/cookies.txt\n","!dir\n","\n","import pandas as pd\n","Xdata = pd.read_excel('datos.xlsx')\n","Xdata.head()\n","Xdata.fillna(Xdata.mean(), inplace=True)\n","Xdata.describe()\n","\n","\n","\n","Xdata=Xdata[['Año', 'Mes', 'TGP',  'salarios reales', 'Indicador de Seguimiento a la Economía',\n","       'imporenta real', 'iva real',\n","       'Tasa de intervención de política monetaria (%)','TD']]#'TD-1','TD-2','TD-3' ,'TD']]\n","Xdata.rename(columns={'Año': 'Year', 'Mes':'Month', 'TGP':'GPR',\n","       'salarios reales':'RS', 'Indicador de Seguimiento a la Economía':'EMI',\n","       'imporenta real':'RIT', 'iva real':'RVT',\n","       'Tasa de intervención de política monetaria (%)':'MPIR','TD':'UR'},inplace=True) #'TD-1':'UR-1','TD-2':'UR-2','TD-3':'UR-3','TD':'UR'}, inplace=True)\n","\n","\n","X_new=Xdata.loc[1:,['GPR','RS','EMI','RIT','RVT','MPIR','UR']]#,\n","Xdata=Xdata.iloc[:-1]\n","Xdata[['GPR-1','RS-1','EMI-1','RIT-1','RVT-1','MPIR-1','UR-1']]=X_new.values#'GPR-1','RS-1','EMI-1','RIT-1','RVT-1','MPIR-1',\n","\n","#Xdata=pd.DataFrame(scaler.fit_transform(Xdata),columns=Xdata.columns)\n","X_new=Xdata.loc[1:,['GPR-1','RS-1','EMI-1','RIT-1','RVT-1','MPIR-1','UR-1']]#'GPR','RS','EMI','RIT','RVT','MPIR',\n","Xdata=Xdata.iloc[:-1]\n","Xdata[['GPR-2','RS-2','EMI-2','RIT-2','RVT-2','MPIR-2','UR-2']]=X_new.values#'GPR-1','RS-1','EMI-1','RIT-1','RVT-1','MPIR-1',\n","\n","#Xdata=pd.DataFrame(scaler.fit_transform(Xdata),columns=Xdata.columns)\n","X_new=Xdata.loc[1:,['GPR-2','RS-2','EMI-2','RIT-2','RVT-2','MPIR-2','UR-2']]#'GPR','RS','EMI','RIT','RVT','MPIR',\n","Xdata=Xdata.iloc[:-1]\n","Xdata[['GPR-3','RS-3','EMI-3','RIT-3','RVT-3','MPIR-3','UR-3']]=X_new.values#'GPR-1','RS-1','EMI-1','RIT-1','RVT-1','MPIR-1',\n","\n","#Xdata=pd.DataFrame(scaler.fit_transform(Xdata),columns=Xdata.columns)\n","X_new=Xdata.loc[1:,['GPR-3','RS-3','EMI-3','RIT-3','RVT-3','MPIR-3','UR-3']]#'GPR','RS','EMI','RIT','RVT','MPIR',\n","Xdata=Xdata.iloc[:-1]\n","Xdata[['GPR-4','RS-4','EMI-4','RIT-4','RVT-4','MPIR-4','UR-4']]=X_new.values#'GPR-1','RS-1','EMI-1','RIT-1','RVT-1','MPIR-1',\n","#Xdata=pd.DataFrame(scaler.fit_transform(Xdata),columns=Xdata.columns)\n","X_new=Xdata.loc[1:,['GPR-4','RS-4','EMI-4','RIT-4','RVT-4','MPIR-4','UR-4']]#'GPR','RS','EMI','RIT','RVT','MPIR',\n","Xdata=Xdata.iloc[:-1]\n","Xdata[['GPR-5','RS-5','EMI-5','RIT-5','RVT-5','MPIR-5','UR-5']]=X_new.values#'GPR-1','RS-1','EMI-1','RIT-1','RVT-1','MPIR-1',\n","# X_new=Xdata.loc[1:,'TD-1']\n","# Xdata=Xdata.iloc[:-1]\n","# Xdata['TD-2']=X_new.values\n","# X_new=Xdata.loc[1:,'TD-2']\n","# Xdata=Xdata.iloc[:-1]\n","# Xdata['TD-3']=X_new.values\n","print(Xdata.info())\n","scaler= MinMaxScaler()\n","Xdata.iloc[:,2:]=scaler.fit_transform(Xdata.iloc[:,2:])\n","X=Xdata.drop(['UR-5','Year','Month'], axis=1).values\n","y=Xdata['UR-5'].values\n","\n","Xdata\n","i=['KRRBF','KNN','GP','Linear','Lasso','Elastic','SGD','BayesRid','RF','SVR']\n","Xdata"]},{"cell_type":"markdown","metadata":{"id":"U6fC7BSCxkbs"},"source":["# Time series cross validation"]},{"cell_type":"markdown","metadata":{"id":"mqU5KgWUEVP0"},"source":["##Classic Economic Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GVBLbdXzEcOr"},"outputs":[],"source":["# Evaluar el modelo ARIMA\n","results_arima = time_series_cv(X,y, model_type='ARIMA',s=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"30oCVw-Ojk6K"},"outputs":[],"source":["# Evaluar el modelo SARIMA\n","results_sarima = time_series_cv(X,y, model_type='SARIMA',s=0,seasonal_order=(3, 3, 3, 2))"]},{"cell_type":"markdown","metadata":{"id":"9_NVM0r7OQDD"},"source":["##Machine Learning Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"udV3oAyRNg_D"},"outputs":[],"source":["results_KRRBF=time_series_cv(X, y,model_type=i[0],s=0,Na='s0')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ElBpZLMlNg1J"},"outputs":[],"source":["results_KNN=time_series_cv(X, y,model_type=i[1],s=0,Na='s0')"]},{"cell_type":"code","source":["results_GP=time_series_cv(X, y,model_type=i[2],s=0,Na='s04')"],"metadata":{"id":"mp0NJ-MYzI-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JznZ5k4KNgjM"},"outputs":[],"source":["results_Linear=time_series_cv(X, y,model_type=i[3],s=0,Na='s01')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZH619MS6NgY8"},"outputs":[],"source":["results_Lasso=time_series_cv(X, y,model_type=i[4],s=0,Na='s03')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tnL2fjRONgRb"},"outputs":[],"source":["##########################\n","results_Elastic=time_series_cv(X, y,model_type=i[5],s=0,Na='s01')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLTLgjXDNgJU"},"outputs":[],"source":["results_SGD=time_series_cv(X, y,model_type=i[6],s=0,Na='s0')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9gPDNzVNgAE"},"outputs":[],"source":["results_BayesRid=time_series_cv(X, y,model_type=i[7],s=0,Na='s0')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqXnIDg7NwOF"},"outputs":[],"source":["results_RF=time_series_cv(X, y,model_type=i[8],s=0,Na='s01')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RsLJVTFsNy-5"},"outputs":[],"source":["results_SVR=time_series_cv(X, y,model_type=i[9],s=0,Na='s0')"]},{"cell_type":"markdown","metadata":{"id":"JAeKO_96x1fp"},"source":["# Sliding Window Cross-Validation"]},{"cell_type":"markdown","metadata":{"id":"19GoDIVOx-zb"},"source":["##Classic Economic Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rU993CexG-ss"},"outputs":[],"source":["# Evaluar el modelo ARIMA\n","results_arima_s = time_series_cv(X,y, model_type='ARIMA',s=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5TF0uQFG_00"},"outputs":[],"source":["# Evaluar el modelo SARIMA\n","results_sarima_s = time_series_cv(X,y, model_type='SARIMA',s=1,seasonal_order=(3, 3, 3, 2))"]},{"cell_type":"markdown","metadata":{"id":"IsElD1WEyNWU"},"source":["##Machine Learning Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4Hve5r5M-sb"},"outputs":[],"source":["results_KRRBF_s=time_series_cv(X, y,model_type=i[0],s=1,Na='s1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZM6H7YRPC39"},"outputs":[],"source":["results_KNN_s=time_series_cv(X, y,model_type=i[1],s=1,Na='s1')"]},{"cell_type":"code","source":[],"metadata":{"id":"DPgUCDRIDSCS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EYuJlSkyQaiG"},"outputs":[],"source":["results_GP_s=time_series_cv(X, y,model_type=i[2],s=1,Na='s12')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mxqy0N3oRZlW"},"outputs":[],"source":["results_Linear_s=time_series_cv(X, y,model_type=i[3],s=1,Na='s1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPQI0_BKVWDV"},"outputs":[],"source":["results_Lasso_s=time_series_cv(X, y,model_type=i[4],s=1,Na='s12')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3lKKhxk0VwNU"},"outputs":[],"source":["results_Elastic_s=time_series_cv(X, y,model_type=i[5],s=1,Na='s19')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ssb-LTLbV7ZD"},"outputs":[],"source":["results_SGD_s=time_series_cv(X, y,model_type=i[6],s=1,Na='s1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PrAng89UWIEt"},"outputs":[],"source":["results_BayesRid_s=time_series_cv(X, y,model_type=i[7],s=1,Na='s1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6QwJIgpWR4z"},"outputs":[],"source":["results_RF_s=time_series_cv(X, y,model_type=i[8],s=1,Na='s11')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p53x7y_gZfik"},"outputs":[],"source":["results_SVR_s=time_series_cv(X, y,model_type=i[9],s=1,Na='s1')"]},{"cell_type":"markdown","metadata":{"id":"9s_DYfaKzgrO"},"source":["#Plots"]},{"cell_type":"code","source":["# Asegúrate de eliminar cualquier instancia previa de grid_search o modelos\n","try:\n","    del grid_search  # Borra el objeto grid_search si existe\n","    del model  # Borra el modelo si existe\n","except NameError:\n","    pass  # Si no existen, continua sin errores\n","\n","# Asumiendo que tienes X, y definidos\n","# División de los datos sin barajar y con un 10% para test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n","\n","# Definición del modelo con los hiperparámetros proporcionados\n","model = GaussianProcessRegressor(\n","    alpha=1,  # El valor inicial, puede ser modificado por GridSearchCV\n","    kernel=RBF(length_scale=np.ones(X.shape[1]), length_scale_bounds=(1, 1000000)),  # Kernel RBF con límites de longitud de escala\n","    normalize_y=True,\n","    random_state=42\n",")\n","\n","# Definición del espacio de hiperparámetros a buscar\n","param_grid = {\n","    'alpha': [1e-5, 1e-3, 1e-1, 1, 10, 1e2] # Buscando en el rango de bounds del length_scale\n","}\n","\n","# Definición de las métricas a evaluar\n","scoring = {\n","    'R2': make_scorer(r2_score),\n","    'MAE': make_scorer(mean_absolute_error, greater_is_better=False)  # Invertido para que la MAE menor sea mejor\n","}\n","\n","# Función para ejecutar GridSearchCV con diferentes folds y recopilar métricas\n","def run_grid_search(cv_folds):\n","    grid_search = GridSearchCV(\n","        estimator=model,\n","        param_grid=param_grid,\n","        cv=cv_folds,\n","        n_jobs=-1,\n","        scoring=scoring,\n","        refit='R2',  # Refit usando R2 como métrica principal\n","        return_train_score=True\n","    )\n","    grid_search.fit(X_train, y_train)\n","    fold_r2_scores = [grid_search.cv_results_[f'split{i}_test_R2'][grid_search.best_index_] for i in range(cv_folds)]\n","    fold_mae_scores = [-grid_search.cv_results_[f'split{i}_test_MAE'][grid_search.best_index_] for i in range(cv_folds)]\n","    return fold_r2_scores, fold_mae_scores\n","\n","# Ejecutar GridSearch con 5 folds y 10 folds\n","r2_scores_5, mae_scores_5 = run_grid_search(5)\n","r2_scores_10, mae_scores_10 = run_grid_search(10)\n","\n"],"metadata":{"id":"i-foPysn6IDf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Asegúrate de que tus datos están definidos y ordenados\n","# Sustituye estas líneas por tus datos reales\n","# r2_scores_5 = np.random.rand(100)\n","# r2_scores_10 = np.random.rand(100)\n","# mae_scores_5 = np.random.rand(100) * 0.1\n","# mae_scores_10 = np.random.rand(100) * 0.1\n","\n","data = [\n","    np.sort(r2_scores_5),\n","    np.sort(r2_scores_10),\n","    np.sort(mae_scores_5),\n","    np.sort(mae_scores_10)\n","]\n","\n","labels = ['R²', 'R²', 'MAE', 'MAE']\n","\n","def adjacent_values(vals, q1, q3):\n","    upper_adjacent_value = q3 + (q3 - q1) * 1.5\n","    upper_adjacent_value = np.clip(upper_adjacent_value, q3, vals[-1])\n","    lower_adjacent_value = q1 - (q3 - q1) * 1.5\n","    lower_adjacent_value = np.clip(lower_adjacent_value, vals[0], q1)\n","    return lower_adjacent_value, upper_adjacent_value\n","\n","def set_axis_style(ax, labels):\n","    ax.set_xticks(np.arange(1, len(labels) + 1), labels=labels)\n","    ax.set_xlim(0.25, len(labels) + 0.75)\n","    ax.set_ylim(0, 1)\n","\n","fig, ax = plt.subplots(figsize=(8, 4))\n","\n","parts = ax.violinplot(\n","    data, showmeans=False, showmedians=False, showextrema=False\n",")\n","\n","# Tonos pastel: azul para R², naranja para MAE\n","violin_colors = ['#aec7e8','#ffbb78','#aec7e8', '#ffbb78']  # tonos pastel\n","\n","scale_factor = 0.3  # Violines delgados para evitar sobresalir\n","\n","for i, (pc, color) in enumerate(zip(parts['bodies'], violin_colors)):\n","    pc.set_facecolor(color)\n","    pc.set_edgecolor('black')\n","    pc.set_alpha(0.9)\n","\n","    # Escalar el ancho del violín\n","    verts = pc.get_paths()[0].vertices\n","    x = verts[:, 0]\n","    x_mean = np.mean(x)\n","    verts[:, 0] = (x - x_mean) * scale_factor + x_mean\n","\n","# Calcular cuartiles y bigotes\n","quartile1, medians, quartile3 = [], [], []\n","\n","for d in data:\n","    q1, med, q3 = np.percentile(d, [25, 50, 75])\n","    quartile1.append(q1)\n","    medians.append(med)\n","    quartile3.append(q3)\n","\n","quartile1 = np.array(quartile1)\n","medians = np.array(medians)\n","quartile3 = np.array(quartile3)\n","\n","whiskers = np.array([\n","    adjacent_values(d, q1, q3) for d, q1, q3 in zip(data, quartile1, quartile3)\n","])\n","whiskers_min, whiskers_max = whiskers[:, 0], whiskers[:, 1]\n","\n","# Posiciones X\n","inds = np.arange(1, len(data) + 1)\n","\n","# Dibujar elementos de boxplot\n","# Dibujar una línea horizontal en la mediana\n","for i, med in enumerate(medians, start=1):\n","    ax.hlines(med, i - 0.01, i + 0.01, color='white', linewidth=1, zorder=10)\n","\n","ax.vlines(inds, quartile1, quartile3, color='k', linestyle='-', lw=5)\n","ax.vlines(inds, whiskers_min, whiskers_max, color='k', linestyle='-', lw=1)\n","\n","# Estilo de ejes y título\n","set_axis_style(ax, labels)\n","plt.tight_layout()\n","plt.ylabel('Score')\n","plt.savefig('CV5-10.pdf')\n","plt.show()\n"],"metadata":{"id":"FHhPibOewbrN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhnImQaejbiB"},"outputs":[],"source":["import pandas as pd\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score, mean_absolute_error\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","def evaluate_model(y_test, y_pred):\n","    mse = mean_squared_error(y_test, y_pred)\n","    rmse = mean_squared_error(y_test, y_pred)\n","    mape = mean_absolute_percentage_error(y_test, y_pred)\n","    r2 = r2_score(y_test, y_pred)\n","    mae =mean_absolute_error(y_test, y_pred)\n","    return mse,rmse,mape,r2,mae\n","# Definición de columnas y etiquetas\n","columnas = ['Model','MSE0', 'MSE1', 'RMSE0', 'RMSE1', 'MAPE0', 'MAPE1', 'MAE0', 'MAE1', 'R20', 'R21']\n","labels = ['ARIMA', 'SARIMA', 'RF', 'Lasso', 'SVR', 'Elastic', 'GP']\n","# Crear el DataFrame vacío\n","df = pd.DataFrame(columns=columnas)\n","# Lista para almacenar las filas\n","filas = []\n","# Bucle para procesar cada modelo\n","for label in labels:\n","    # Cargar datos\n","    data0 = pd.read_excel(f'/content/drive/MyDrive/Doctorado/Optimización/3 Meses/Results/{label}_0.xlsx')\n","    data1 = pd.read_excel(f'/content/drive/MyDrive/Doctorado/Optimización/3 Meses/Results/{label}_1.xlsx')\n","    # Extraer valores\n","    y_test = data0['y_true'].values\n","    y_pred0 = data0['y_pred'].values\n","    y_pred1 = data1['y_pred'].values\n","    # Calcular métricas\n","    mse0, rmse0, mape0, r20, mae0 = evaluate_model(y_test, y_pred0)\n","    mse1, rmse1, mape1, r21, mae1 = evaluate_model(y_test, y_pred1)\n","    # Crear nueva fila\n","    nueva_fila = pd.Series([label,mse0, mse1, rmse0, rmse1, mape0, mape1, mae0, mae1, r20, r21], index=columnas)\n","    # Agregar la nueva fila a la lista de filas\n","    filas.append(nueva_fila)\n","# Concatenar todas las filas en un único DataFrame\n","df = pd.concat(filas, axis=1).T.reset_index(drop=True)\n","# Mostrar el DataFrame resultante\n","#df.to_excel('/content/drive/MyDrive/Doctorado/Optimización/Results.xlsx')\n","df"]},{"cell_type":"code","source":["import pandas as pd\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score, mean_absolute_error\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","def evaluate_model(y_test, y_pred):\n","    mse = mean_squared_error(y_test, y_pred)\n","    rmse = mean_squared_error(y_test, y_pred)\n","    mape = mean_absolute_percentage_error(y_test, y_pred)\n","    r2 = r2_score(y_test, y_pred)\n","    mae =mean_absolute_error(y_test, y_pred)\n","    return mse,rmse,mape,r2,mae\n","# Definición de columnas y etiquetas\n","columnas = ['Model','MSE0', 'MSE1', 'RMSE0', 'RMSE1', 'MAPE0', 'MAPE1', 'MAE0', 'MAE1', 'R20', 'R21']\n","labels = ['ARIMA', 'SARIMA', 'RF', 'Lasso', 'SVR', 'Elastic', 'GP']\n","\n","# Crear el DataFrame vacío\n","df = pd.DataFrame(columns=columnas)\n","\n","# Lista para almacenar las filas\n","filas = []\n","\n","# Bucle para procesar cada modelo\n","for label in labels:\n","    # Cargar datos\n","    data0 = pd.read_excel(f'/content/drive/MyDrive/Doctorado/Optimización/12 Meses/Results/{label}_0.xlsx')\n","    data1 = pd.read_excel(f'/content/drive/MyDrive/Doctorado/Optimización/12 Meses/Results/{label}_1.xlsx')\n","\n","    # Extraer valores\n","    y_test = data0['y_true'].values\n","    y_pred0 = data0['y_pred'].values\n","    y_pred1 = data1['y_pred'].values\n","\n","    # Calcular métricas\n","    mse0, rmse0, mape0, r20, mae0 = evaluate_model(y_test, y_pred0)\n","    mse1, rmse1, mape1, r21, mae1 = evaluate_model(y_test, y_pred1)\n","    # Crear nueva fila\n","    nueva_fila = pd.Series([label,mse0, mse1, rmse0, rmse1, mape0, mape1, mae0, mae1, r20, r21], index=columnas)\n","\n","    # Agregar la nueva fila a la lista de filas\n","    filas.append(nueva_fila)\n","\n","# Concatenar todas las filas en un único DataFrame\n","df = pd.concat(filas, axis=1).T.reset_index(drop=True)\n","# Mostrar el DataFrame resultante\n","#df.to_excel('/content/drive/MyDrive/Doctorado/Optimización/Results.xlsx')\n","df"],"metadata":{"id":"du2JoKqhs2o7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Xdata"],"metadata":{"id":"7qaOm_hlUMJE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Xdata=pd.DataFrame(scaler.inverse_transform(Xdata.values),columns=Xdata.columns)\n","# Xdata['Year']=Xdata['Year'].astype(np.int64)\n","# Xdata['Month']=Xdata['Month'].astype(np.int64)"],"metadata":{"id":"An_QIHlPUHox"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Xdata"],"metadata":{"id":"23jZwWAqUp7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"w_IPl255U0El"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ytC0LzxdzHwM"},"outputs":[],"source":["# Colores para los splits\n","# Colores para los splits\n","# Renombrar columnas para que sean compatibles con pd.to_datetime\n","#Xdata.rename(columns={'Año': 'year', 'Mes': 'month'}, inplace=True)\n","\n","# Convertir 'year' y 'month' en un objeto de fecha y establecerlo como índice\n","\n","Xdata['Fecha'] = pd.to_datetime(Xdata[['Year', 'Month']].assign(day=1))\n","Xdata = Xdata.set_index('Fecha')\n","# Añadir un punto para el año 2024\n","data_filtered = Xdata[(Xdata.index.month == 1) | (Xdata.index.month == 12)]\n","dates = data_filtered.index\n","annual_data = Xdata.resample('Y').mean()\n","years = annual_data.index\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n","from statsmodels.tsa.seasonal import seasonal_decompose\n","def obtener_indices_incrustados(tamano_total, tamano_ventana, cantidad_incrustada):\n","    indices = []\n","\n","    # Recorremos las ventanas\n","    for i in range(0, tamano_total, tamano_ventana):\n","        indices.extend(range(i, min(i + cantidad_incrustada, tamano_total)))\n","\n","    # Verificar si hay que completar con los últimos N índices\n","    tamano_actual = len(indices)\n","    tamano_deseado = (tamano_total // tamano_ventana) * cantidad_incrustada+cantidad_incrustada\n","\n","    if tamano_actual < tamano_total:\n","        indices.extend(range(tamano_total - (tamano_deseado - tamano_actual), tamano_total))\n","\n","    return indices\n","\n","\n","# Leer los datos de la base de datos\n","data = Xdata.copy()\n","\n","# Renombrar columnas para que sean compatibles con pd.to_datetime\n","#data.rename(columns={'Año': 'year', 'Mes': 'month'}, inplace=True)\n","\n","# Convertir 'year' y 'month' en un objeto de fecha y establecerlo como índice\n","data['Fecha'] = pd.to_datetime(data[['Year', 'Month']].assign(day=2))\n","data = data.set_index('Fecha')\n","annual_data = data.resample('Y').agg({'Year': 'first', 'Month': 'first', 'UR-5': 'mean'})\n","annual_data['Fecha'] = pd.to_datetime(annual_data[['Year', 'Month']].assign(day=1))\n","annual_data = annual_data.set_index('Fecha')\n","\n","# Definir el número de splits y generar los splits una vez\n","n_splits = 70\n","tscv = TimeSeriesSplit(n_splits=n_splits)\n","\n","# Asumiendo que y son tus datos de valor agrupados por año\n","y = data['UR'].values  # Reemplaza 'value' con el nombre de tu columna de datos\n","years = annual_data.index  # Obtener los años\n","\n","# Colores para los splits\n","colors = plt.cm.viridis(np.linspace(0, 1, 80))\n","\n","# Variables para almacenar las métricas\n","mse_scores = []\n","rmse_scores = []\n","mape_scores = []\n","r2_scores = []\n","\n","# Descomposición estacional de la serie temporal\n","decomposition = seasonal_decompose(data['UR'], model='additive', period=12)\n","trend = decomposition.trend\n","seasonal = decomposition.seasonal\n","residual = decomposition.resid\n","\n","# Crear las gráficas\n","fig, axs = plt.subplots(figsize=(20, 16))\n","\n","# Gráfica 1: Valores medios por año y particiones usadas en test\n","axs.plot(data['UR-5'].index, data['UR-5'].values, color='black')\n","i = 0  # Inicializar el contador para los colores\n","i = 0  # Inicializar el contador para los colores\n","train_years = 1  # Años para entrenamiento\n","test_months = 12  # Meses para predicción\n","step_months = 6  # Meses para mover hacia adelante\n","\n","\n","for ind in range(12, data.shape[0] - test_months + 1, step_months):\n","    # Definir los intervalos de entrenamiento y prueba\n","    X_train, y_train = data.iloc[ind - train_years * 12:ind], y[ind - train_years * 12:ind]\n","    X_test, y_test = data.iloc[ind:ind + test_months], y[ind:ind + test_months]\n","\n","    # Añadir la franja vertical para los períodos de test\n","    axs.axvspan(data.index[ind], data.index[ind + test_months - 1], facecolor=colors[i], alpha=0.3)\n","\n","    i += 1  # Incrementar el índice del color\n","\n","# Asegurar que los últimos 6 meses estén pintados si son el último set de predicción\n","axs.set_xticks(years)\n","axs.set_xticklabels(years.year, rotation=45)\n","axs.set_yscale('log')\n","plt.tight_layout()\n","pdf_path = 'Split.pdf'\n","plt.savefig(pdf_path)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7lm42eZ7vL9"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from statsmodels.tsa.seasonal import STL\n","def obtener_indices_incrustados(tamano_total, tamano_ventana, cantidad_incrustada):\n","    indices = []\n","\n","    # Recorremos las ventanas\n","    for i in range(0, tamano_total, tamano_ventana):\n","        indices.extend(range(i, min(i + cantidad_incrustada, tamano_total)))\n","\n","    # Verificar si hay que completar con los últimos N índices\n","    tamano_actual = len(indices)\n","    tamano_deseado = (tamano_total // tamano_ventana) * cantidad_incrustada+cantidad_incrustada\n","\n","    if tamano_actual < tamano_total:\n","        indices.extend(range(tamano_total - (tamano_deseado - tamano_actual), tamano_total))\n","\n","    return indices\n","def plot_decomposition_and_models_combined(data, labels, highlight_periods, highlight_lines, params):\n","    \"\"\"\n","    Genera una figura con 6 subplots organizados en 2 filas y 3 columnas:\n","    dos conjuntos de gráficas con predicciones de modelos y descomposición estacional.\n","    Para el modelo GP, se agrega una banda de confianza utilizando la columna y_std.\n","\n","    :param data: DataFrame con los datos originales\n","    :param labels: Lista de listas con etiquetas de los modelos para los dos conjuntos\n","    :param highlight_periods: Lista de períodos a destacar con franjas\n","    :param highlight_lines: Lista de fechas a destacar con líneas verticales\n","    :param params: Lista de listas de parámetros para los dos conjuntos [periodo, cantidad_incrustada, fold]\n","    \"\"\"\n","\n","    # Crear una figura con 6 subplots en 2 filas y 3 columnas\n","    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n","\n","    def plot_individual_set(axes, row, data, labels1, labels2, highlight_periods, highlight_lines, params):\n","        periodo, cantidad_incrustada, fold = params\n","        tamano_total = len(data)\n","        tamano_ventana = periodo\n","\n","        indices_resultantes = obtener_indices_incrustados(tamano_total, tamano_ventana, cantidad_incrustada)\n","\n","        # Gráfica 1\n","        for label in labels1:\n","            data0 = pd.read_excel(f'/content/drive/MyDrive/Doctorado/Optimización/{fold}/Results/{label}_0.xlsx')\n","            y_pred0 = data0['y_pred'].values\n","            indices_resultantes = obtener_indices_incrustados(len(y_pred0), tamano_ventana, cantidad_incrustada)\n","            y_pred0 = y_pred0[indices_resultantes]\n","            if label == 'GP' and 'y_std' in data0.columns:\n","                y_std = data0['y_std'].values[indices_resultantes]\n","                lower_bound = y_pred0 - 1.96 * y_std\n","                upper_bound = y_pred0 + 1.96 * y_std\n","                #axes[row, 0].fill_between(data.index[12:-1], lower_bound, upper_bound, color='green', alpha=0.3, label=f'{label} 95% CI')\n","\n","            axes[row, 0].plot(data.index[12:-1], y_pred0, label=label)\n","\n","        axes[row, 0].plot(data.index[12:-1], data0['y_true'].values[indices_resultantes], color='black')\n","\n","        # Ajuste del eje X para mostrar fechas completas\n","        axes[row, 0].set_xticks(data.index[12:-1][::int(len(data)/10)])  # Mostrar 10 fechas distribuidas en el eje X\n","        axes[row, 0].set_xticklabels(data.index.strftime('%Y-%m')[12:-1][::int(len(data)/10)], rotation=45)\n","        axes[row, 0].grid(True, linestyle='--', alpha=0.7)\n","        axes[row, 0].legend()\n","        axes[row, 0].set_yscale('log')\n","\n","        for start, end in highlight_periods:\n","            axes[row, 0].axvspan(pd.to_datetime(start), pd.to_datetime(end), color='bisque', alpha=0.3)\n","\n","        for start, end in highlight_lines:\n","            axes[row, 0].axvline(pd.to_datetime(start), color='black', linestyle='--')\n","\n","        # Gráfica 2\n","        for label in labels2:\n","            data0 = pd.read_excel(f'/content/drive/MyDrive/Doctorado/Optimización/{fold}/Results/{label}_1.xlsx')\n","            y_pred0 = data0['y_pred'].values\n","            indices_resultantes = obtener_indices_incrustados(len(y_pred0), tamano_ventana, cantidad_incrustada)\n","            y_pred0 = y_pred0[indices_resultantes]\n","            if label == 'GP' and 'y_std' in data0.columns:\n","                y_std = data0['y_std'].values[indices_resultantes]\n","                lower_bound = y_pred0 - 1.96 * y_std\n","                upper_bound = y_pred0 + 1.96 * y_std\n","                #axes[row, 1].fill_between(data.index[12:-1], lower_bound, upper_bound, color='green', alpha=0.3, label=f'{label} 95% CI')\n","\n","            axes[row, 1].plot(data.index[12:-1], y_pred0, label=label, linestyle='--')\n","\n","        axes[row, 1].plot(data.index[12:-1],data0['y_true'].values[indices_resultantes], color='black', linestyle='--')\n","\n","        # Ajuste del eje X para mostrar fechas completas\n","        axes[row, 1].set_xticks(data.index[12:-1][::int(len(data)/10)])  # Mostrar 10 fechas distribuidas en el eje X\n","        axes[row, 1].set_xticklabels(data.index.strftime('%Y-%m')[12:-1][::int(len(data)/10)], rotation=45)\n","        axes[row, 1].grid(True, linestyle='--', alpha=0.7)\n","        axes[row, 1].legend()\n","        axes[row, 1].set_yscale('log')\n","\n","        for start, end in highlight_periods:\n","            axes[row, 1].axvspan(pd.to_datetime(start), pd.to_datetime(end), color='bisque', alpha=0.3)\n","\n","        for start, end in highlight_lines:\n","            axes[row, 1].axvline(pd.to_datetime(start), color='black', linestyle='--')\n","\n","        # Descomposición estacional\n","        stl = STL(data0['y_true'].values[indices_resultantes], period=periodo)\n","        result = stl.fit()\n","\n","        seasonal = result.seasonal\n","        trend = result.trend - result.trend.mean()\n","        residual = result.resid\n","\n","        axes[row, 2].plot(data.index[12:-1], trend, label='Trend', color='purple', linestyle='-')\n","        axes[row, 2].plot(data.index[12:-1], seasonal, label='Seasonality', color='red', linestyle='--')\n","        axes[row, 2].plot(data.index[12:-1], residual, label='Residual', color='blue', linestyle='-.')\n","\n","        # Ajuste del eje X para mostrar fechas completas\n","        axes[row, 2].set_xticks(data.index[12:-1][::int(len(data)/10)])  # Mostrar 10 fechas distribuidas en el eje X\n","        axes[row, 2].set_xticklabels(data.index[12:-1].strftime('%Y-%m')[::int(len(data)/10)], rotation=45)\n","        axes[row, 2].grid(True, linestyle='--', alpha=0.7)\n","        axes[row, 2].legend()\n","\n","        for start, end in highlight_periods:\n","            axes[row, 2].axvspan(pd.to_datetime(start), pd.to_datetime(end), color='bisque', alpha=0.3)\n","\n","        for start, end in highlight_lines:\n","            axes[row, 2].axvline(pd.to_datetime(start), color='black', linestyle='--')\n","\n","    # Plotea el primer conjunto de gráficas en la primera fila\n","    plot_individual_set(axes, 0, data, labels[0], labels[1], highlight_periods, highlight_lines, params[0])\n","\n","    # Plotea el segundo conjunto de gráficas en la segunda fila\n","    plot_individual_set(axes, 1, data, labels[0], labels[1], highlight_periods, highlight_lines, params[1])\n","\n","    plt.tight_layout()\n","    plt.savefig('PaperDM_combined.pdf')\n","    plt.show()\n","\n","# Ejemplo de uso:\n","highlight_periods = [('2008-01-01', '2008-12-31'), ('2019-11-25', '2023-05-05')]\n","highlight_lines = [('2006-08-07', '2010-08-07'), ('2010-08-07', '2014-08-07'), ('2014-08-07', '2018-08-07'), ('2018-08-07', '2022-08-07'),('2022-08-07','2026-08-07')]\n","\n","labels = [['ARIMA', 'Lasso', 'GP'], ['ARIMA', 'Lasso', 'GP']]\n","params = [[3, 3, '3 Meses'], [12, 6, '12 Meses']]\n","plot_decomposition_and_models_combined(Xdata.copy(), labels, highlight_periods, highlight_lines, params)\n","\n"]},{"cell_type":"code","source":["Xdata"],"metadata":{"id":"pEhxc4aVQcTS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ApGGfzLwueb6"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","def obtener_indices_filtrados(data, step):\n","    \"\"\"\n","    Filtra los índices de un DataFrame o Series a partir del primer año,\n","    tomando cada 'step' datos.\n","\n","    :param data: DataFrame o Series con un índice de tipo datetime\n","    :param step: Paso para seleccionar los datos (3 o 6, por ejemplo)\n","    :return: Índices filtrados\n","    \"\"\"\n","    first_year = data.index[0].year\n","    data_after_first_year = data[data.index.year > first_year]\n","    selected_indices = data_after_first_year.index[::step]\n","    return selected_indices\n","\n","def filtrar_etiquetas(selected_dates, interval):\n","    \"\"\"\n","    Filtra las etiquetas para mostrar solo cada cierto número de meses.\n","\n","    :param selected_dates: Lista de fechas seleccionadas\n","    :param interval: Intervalo de meses para filtrar las etiquetas\n","    :return: Fechas filtradas\n","    \"\"\"\n","    return selected_dates[::interval]\n","\n","def plot_dual_axis(ax1, label, y1_col, y2_col, params, yscale='linear', selected_dates=None, interval=6, highlight_periods=None):\n","    \"\"\"\n","    Genera una gráfica con dos ejes y en un subplote específico.\n","\n","    :param ax1: El eje principal donde se dibujará la gráfica\n","    :param label: El nombre del modelo (ARIMA, Elastic, GP)\n","    :param y1_col: Nombre de la columna para el primer eje y\n","    :param y2_col: Nombre de la columna para el segundo eje y\n","    :param params: Lista de parámetros [periodo, cantidad_incrustada, fold]\n","    :param yscale: Escala para los ejes y ('linear' o 'log')\n","    :param selected_dates: Fechas seleccionadas para etiquetar el eje X\n","    :param interval: Intervalo de meses para filtrar las etiquetas del eje X\n","    :param highlight_periods: Lista de períodos a destacar con franjas\n","    \"\"\"\n","    data0 = pd.read_excel(f'/content/drive/MyDrive/Doctorado/Optimización/{params[2]}/Params/{label}_0.xlsx')\n","    data1 = pd.read_excel(f'/content/drive/MyDrive/Doctorado/Optimización/{params[2]}/Params/{label}_1.xlsx')\n","    if label=='GP':\n","        data0['length_scale']=np.array(data0['length_scale'].apply(lambda x: list(map(float, x.strip('[]').split()))).to_list()).mean(axis=1)\n","\n","        data1['length_scale']=np.array(data1['length_scale'].apply(lambda x: list(map(float, x.strip('[]').split()))).to_list()).mean(axis=1)\n","\n","\n","    if label in ['ARIMA', 'SARIMA']:\n","        data0['order'] = data0['order'].astype(str)\n","        data0[['p', 'd', 'q']] = data0['order'].str.extract(r'\\((\\d+), (\\d+), (\\d+)\\)')\n","        data0[['p', 'd', 'q']] = data0[['p', 'd', 'q']].astype(int)\n","        data0 = data0.drop(columns=['order'])\n","\n","        data1['order'] = data1['order'].astype(str)\n","        data1[['p', 'd', 'q']] = data1['order'].str.extract(r'\\((\\d+), (\\d+), (\\d+)\\)')\n","        data1[['p', 'd', 'q']] = data1[['p', 'd', 'q']].astype(int)\n","        data1 = data1.drop(columns=(['order']))\n","    y1 = data0[y1_col].values\n","    y2 = data0[y2_col].values\n","    y1_1 = data1[y1_col].values\n","    y2_1 = data1[y2_col].values\n","    ax1.plot(selected_dates,y1, color='blue', label=f'{y1_col} ({label})')\n","    ax1.tick_params(axis='y', labelcolor='blue')\n","    ax1.grid(True, linestyle='--', alpha=0.7)\n","\n","    ax2 = ax1.twinx()\n","    ax2.plot(selected_dates,y2, color='black', label=f'{y2_col} ({label})')\n","    ax2.tick_params(axis='y', labelcolor='black')\n","\n","    ax1.set_yscale(yscale,linthresh=0.01)\n","    ax2.set_yscale(yscale,linthresh=0.01)\n","\n","\n","    ax1.plot(selected_dates,y1_1, color='blue', linestyle='--', label=f'{y1_col}_1 ({label})')\n","    ax2.plot(selected_dates,y2_1, color='black', linestyle='--', label=f'{y2_col}_1 ({label})')\n","\n","\n","    # Ajustar las etiquetas del eje X usando las fechas seleccionadas y filtradas\n","    if selected_dates is not None:\n","        filtered_dates = filtrar_etiquetas(selected_dates, interval)\n","        ax1.set_xticks(filtered_dates)  # Usar fechas directamente como ticks\n","        ax1.set_xticklabels([date.strftime('%Y-%m') for date in filtered_dates], rotation=45)\n","\n","    # Resaltar períodos específicos con franjas\n","    if highlight_periods is not None:\n","        for start, end in highlight_periods:\n","            ax1.axvspan(pd.to_datetime(start), pd.to_datetime(end), color='bisque', alpha=0.3)\n","            ax2.axvspan(pd.to_datetime(start), pd.to_datetime(end), color='bisque', alpha=0.3)\n","    ax1.legend(loc='upper left')\n","    ax2.legend(loc='upper right')\n","\n","# Función para limpiar y convertir cadenas en listas solo si son strings\n","def limpiar_y_convertir(cadena):\n","    #if isinstance(cadena, str):\n","    cadena = cadena.replace(',,', ' ').replace(' ', ',')\n","    try:\n","        return eval(cadena)  # Convertir la cadena a una lista\n","    except SyntaxError:\n","        return []  # Retornar una lista vacía en caso de error\n","    #elif isinstance(cadena, list):\n","    #    return cadena  # Si ya es una lista, devolverla tal cual\n","    #else:\n","    #    return []  # Manejar otros tipos como prefieras\n","def plot_all_models(labels, y1_cols, y2_cols, yscales, params_list, data, highlight_periods=None):\n","    \"\"\"\n","    Genera una figura con múltiples filas de subplots en función de la cantidad de listas en params_list.\n","\n","    :param labels: Lista de nombres de los modelos\n","    :param y1_cols: Lista de nombres de las columnas para el primer eje y\n","    :param y2_cols: Lista de nombres de las columnas para el segundo eje y\n","    :param yscales: Lista de escalas para los ejes y\n","    :param params_list: Lista de listas de parámetros para cada conjunto de gráficos\n","    :param data: DataFrame con el índice de tipo datetime\n","    :param highlight_periods: Lista de períodos a destacar con franjas\n","    \"\"\"\n","    num_rows = len(params_list)\n","    num_cols = len(labels)\n","\n","    fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, 6 * num_rows))\n","\n","    for i, params in enumerate(params_list):\n","        step = params[1]  # Usar el paso especificado en los parámetros\n","        if i==0:\n","            selected_dates = obtener_indices_filtrados(data, step)[:-1]\n","        else:\n","            selected_dates = obtener_indices_filtrados(data,6)[:-2]\n","        interval = 6 if i == 0 else 3  # Usar 6 meses para la primera fila y 3 meses para la segunda\n","        for j, label in enumerate(labels):\n","            if num_rows > 1:\n","                ax = axes[i, j]\n","            else:\n","                ax = axes[j]\n","            plot_dual_axis(ax, label, y1_cols[j], y2_cols[j], params, yscale=yscales[j], selected_dates=selected_dates, interval=interval, highlight_periods=highlight_periods)\n","\n","    plt.tight_layout()\n","    plt.savefig('PaperDMP.pdf')\n","    plt.show()\n","\n","# Ejemplo de uso\n","labels = ['ARIMA', 'Elastic', 'GP']\n","y1_cols = ['p', 'l1_ratio', 'length_scale']\n","y2_cols = ['q', 'alpha', 'alpha']\n","yscales = ['symlog', 'symlog', 'symlog']\n","params_list = [[12, 3, '3 Meses'], [12, 6, '12 Meses']]\n","\n","# Definir los períodos a resaltar con franjas\n","highlight_periods = [('2008-01-01', '2008-12-31'), ('2019-11-25', '2023-05-05')]\n","\n","# Supongamos que este es tu DataFrame con un índice de tipo datetime\n","# data = pd.DataFrame(...)\n","\n","plot_all_models(labels, y1_cols, y2_cols, yscales, params_list, data, highlight_periods)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vCzhHDQewy-E"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Función para cargar y normalizar datos desde un archivo Excel\n","def cargar_y_normalizar(archivo, columna=None,s=0):\n","    df = pd.read_excel(archivo)\n","    if columna:\n","        df=pd.DataFrame(np.array(df[columna].apply(lambda x: list(map(float, x.strip('[]').split()))).to_list()))\n","        a=1/df.mean(axis=0)\n","        normalizado = abs((a/a.abs().sum()))\n","    elif i==0 or i==3:\n","        df = df.iloc[:, 1:]  # Seleccionar columnas necesarias cuando no se especifica columna\n","        normalizado = abs((df.mean(axis=0) / df.mean(axis=0).abs().sum()))  # Normalizar\n","    else:\n","        df = df.iloc[:, 2:]  # Seleccionar columnas necesarias cuando no se especifica columna\n","        normalizado = abs((df.mean(axis=0) / df.mean(axis=0).abs().sum()))  # Normalizar\n","    return normalizado.values\n","\n","# Función para limpiar y convertir cadenas en listas solo si son strings\n","def limpiar_y_convertir(cadena):\n","    if isinstance(cadena, str):\n","        cadena = cadena.replace(',,', ' ').replace(' ', ',')\n","        try:\n","            return eval(cadena)  # Convertir la cadena a una lista\n","        except SyntaxError:\n","            return []  # Retornar una lista vacía en caso de error\n","    elif isinstance(cadena, list):\n","        return cadena  # Si ya es una lista, devolverla tal cual\n","    else:\n","        return []  # Manejar otros tipos como prefieras\n","\n","# Función para graficar los datos normalizados en un subplot\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def graficar_normalizado(normalizado, etiquetas, ax):\n","    ax.bar(np.arange(len(etiquetas)), normalizado, color='skyblue')\n","    # Estas etiquetas se asignan por defecto, pero luego\n","    # las “borramos” según la posición de la celda.\n","    ax.set_xlabel('Columns')\n","    ax.set_ylabel('Normalized Value')\n","    ax.set_title('Normalized Values by Column')\n","    ax.set_xticks(np.arange(len(etiquetas)))\n","    ax.set_xticklabels(etiquetas, rotation=90)\n","\n","def procesar_y_graficar(archivos, etiquetas, titulo, columna=None, nrows=1, ncols=2):\n","    fig, axs = plt.subplots(nrows, ncols, figsize=(14, 6))\n","    # Si solo hay una fila o una columna, axs podría no ser\n","    # un array bidimensional, sino un array 1D o incluso un solo eje.\n","    # Para simplificar, convertimos todo a una lista plana de ejes.\n","    axs = np.array(axs).reshape(nrows, ncols)\n","    for idx, archivo in enumerate(archivos):\n","        # Calculamos en qué fila y columna estamos\n","        row = idx // ncols\n","        col = idx % ncols\n","        # Cargar y normalizar datos\n","        normalizado = cargar_y_normalizar(archivo, columna)\n","        # Graficar en el subplot correspondiente\n","        graficar_normalizado(normalizado, etiquetas, axs[row, col])\n","        # Si NO estamos en la última fila, quitamos el xlabel\n","        if row != nrows - 1:\n","            print(1)\n","            axs[row, col].set_xlabel('')\n","        # Si NO estamos en la primera columna, quitamos el ylabel\n","        if col != 0:\n","            axs[row, col].set_ylabel('')\n","    plt.suptitle(titulo)\n","    plt.tight_layout()\n","    plt.show()\n","\n","import re\n","import pandas as pd\n","def renombrar(col):\n","    \"\"\"\n","    Si la columna col es del tipo Prefijo(-sufijo),\n","    donde Prefijo está en [GPR, RS, EMI, RIT, RVT, MPIR, UR]\n","    y sufijo es opcionalmente un dígito (1..5),\n","    la renombramos siguiendo el mapeo:\n","       \"\"   ->  \"5\"\n","       \"1\"  ->  \"4\"\n","       \"2\"  ->  \"3\"\n","       \"3\"  ->  \"2\"\n","       \"4\"  ->  \"1\"\n","       \"5\"  ->  \"\"\n","    De lo contrario, devolvemos la misma columna (ej. Year, Month).\n","    \"\"\"\n","    pattern = r'^(GPR|RS|EMI|RIT|RVT|MPIR|UR)(?:-(\\d))?$'\n","    m = re.match(pattern, col)\n","    if m:\n","        prefijo = m.group(1)              # p.e. \"GPR\", \"RS\", etc.\n","        sufijo_original = m.group(2) or \"\"  # p.e. \"1\", \"2\", ..., ó \"\" si no había\n","\n","        # Tabla de mapeo\n","        mapa_sufijos = {\n","            \"\":  \"5\",\n","            \"1\": \"4\",\n","            \"2\": \"3\",\n","            \"3\": \"2\",\n","            \"4\": \"1\",\n","            \"5\": \"\"\n","        }\n","\n","        sufijo_nuevo = mapa_sufijos[sufijo_original]\n","\n","        if sufijo_nuevo == \"\":\n","            return prefijo       # p.e. \"GPR\" si quedó sin sufijo\n","        else:\n","            return f\"{prefijo}-{sufijo_nuevo}\"\n","    else:\n","        return col\n","\n","# --- Aplicamos el renombrado ---\n","Xdata= Xdata.rename(columns=renombrar)\n","# Definir las etiquetas\n","try:\n","    b = Xdata.drop(['UR', 'Year', 'Month'], axis=1).columns\n","except:\n","    b = Xdata\n","\n","# Archivos y configuraciones de 12 meses y 3 meses\n","archivos_12_meses = [\n","\n","    ('/content/drive/MyDrive/Doctorado/Optimización/12 Meses/Params/Lasso_0.xlsx', None),\n","    ('/content/drive/MyDrive/Doctorado/Optimización/12 Meses/Params/RF_0.xlsx', None),\n","    ('/content/drive/MyDrive/Doctorado/Optimización/12 Meses/Params/GP_0.xlsx', 'length_scale'),\n","\n","    ('/content/drive/MyDrive/Doctorado/Optimización/12 Meses/Params/Lasso_1.xlsx', None),\n","    ('/content/drive/MyDrive/Doctorado/Optimización/12 Meses/Params/RF_1.xlsx', None),\n","    ('/content/drive/MyDrive/Doctorado/Optimización/12 Meses/Params/GP_1.xlsx', 'length_scale')\n","]\n","\n","archivos_3_meses = [\n","\n","    ('/content/drive/MyDrive/Doctorado/Optimización/3 Meses/Params/Lasso_0.xlsx', None),\n","    ('/content/drive/MyDrive/Doctorado/Optimización/3 Meses/Params/RF_0.xlsx', None),\n","    ('/content/drive/MyDrive/Doctorado/Optimización/3 Meses/Params/GP_0.xlsx', 'length_scale'),\n","    ('/content/drive/MyDrive/Doctorado/Optimización/3 Meses/Params/Lasso_1.xlsx', None),\n","    ('/content/drive/MyDrive/Doctorado/Optimización/3 Meses/Params/RF_1.xlsx', None),\n","    ('/content/drive/MyDrive/Doctorado/Optimización/3 Meses/Params/GP_1.xlsx', 'length_scale'),\n","]\n","fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n","names=['Lasso','Random forest', 'Gaussian process']\n","for i, (archivo, columna) in enumerate(archivos_3_meses):\n","    # Calcula la posición en la grilla\n","    row = i // 3\n","    col = i % 3\n","    # Carga y normaliza\n","    normalizado = cargar_y_normalizar(archivo, columna, s=i)\n","    # Dibuja en el subplot [row, col]\n","    graficar_normalizado(normalizado, b, axs[row, col])\n","    # Quitar el X-label si NO estamos en la última fila\n","    if row != 0:  # 1 es la última fila (con nrows=2)\n","        axs[row, col].set_title('')\n","    else:\n","        axs[row, col].set_title(names[i])\n","    axs[row, col].set_xlabel('')\n","    # Quitar el Y-label si NO estamos en la primera columna\n","    #if col != 0:\n","    axs[row, col].set_ylabel('')\n","fig.supylabel('Feature relevance', x=-0.001, fontsize=12)\n","\n","plt.tight_layout()\n","plt.savefig('Inter3M.pdf')\n","plt.show()\n","\n","\n"]},{"cell_type":"code","source":["\n","#plt.xticklabels(columna, rotation=90)"],"metadata":{"id":"Ybtvyv7jj9mv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["b"],"metadata":{"id":"Bmvse6luidbC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["axs=plt.figure(figsize=(10, 4))\n","archivo, columna =  ('/content/drive/MyDrive/Doctorado/Optimización/12 Meses/Params/GP_1.xlsx', 'length_scale')\n","normalizado = cargar_y_normalizar(archivo, columna, s=i)\n","plt.bar(np.arange(len(b)), normalizado, color='skyblue')\n","# Estas etiquetas se asignan por defecto, pero luego\n","# las “borramos” según la posición de la celda.\n","plt.yticks([])\n","plt.xlabel('Feature')\n","plt.xticks(np.arange(len(b)),labels=b, rotation=90,fontsize=16)\n","plt.tight_layout()\n","plt.show()\n","#plt.xticklabels(columna, rotation=90)"],"metadata":{"id":"EqdW59o7COhM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Xdata.columns"],"metadata":{"id":"anYWVmF6jbC0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6nlriOTe3yXt"},"outputs":[],"source":["# Graficar los datos de 12 meses en una figura\n","fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n","for i, (archivo, columna) in enumerate(archivos_12_meses):\n","    # Calcula la posición en la grilla\n","    row = i // 3\n","    col = i % 3\n","    # Carga y normaliza\n","    normalizado = cargar_y_normalizar(archivo, columna, s=i)\n","    # Dibuja en el subplot [row, col]\n","    graficar_normalizado(normalizado, b, axs[row, col])\n","    # Quitar el X-label si NO estamos en la última fila\n","    if row != 0:  # 1 es la última fila (con nrows=2)\n","        axs[row, col].set_title('')\n","    else:\n","        axs[row, col].set_title(names[i])\n","    axs[row, col].set_xlabel('')\n","    # Quitar el Y-label si NO estamos en la primera columna\n","    #if col != 0:\n","    axs[row, col].set_ylabel('')\n","fig.supylabel('Feature relevance', x=-0.001, fontsize=12)\n","\n","plt.tight_layout()\n","plt.savefig('Inter6M.pdf')\n","plt.show()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"2x70l40lkHxq"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["CGGIGYweOG-N","U6fC7BSCxkbs","mqU5KgWUEVP0","JAeKO_96x1fp","19GoDIVOx-zb"],"mount_file_id":"1kDI7RWZPImfT79DRTFA25iMC5K-pbRcG","authorship_tag":"ABX9TyNcJaI+kelATnZKAE2JCMrs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}